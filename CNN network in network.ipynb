{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "注意到卷积神经网络一般分成两块，一块主要由卷积层构成，另一块主要是全连接层。在Alexnet里我们看到如何把卷积层块和全连接层分别加深加宽从而得到深度网络。另外一个自然的想法是，我们可以串联数个卷积层块和全连接层块来构建深度网络。\n",
    "不过这里的一个难题是，卷积的输入输出是4D矩阵，然而全连接是2D。同时在卷积神经网络里我们提到如果把4D矩阵转成2D做全连接，这个会导致全连接层有过多的参数。NiN提出只对通道层做全连接并且像素之间共享权重来解决上述两个问题。就是说，我们使用kernel大小是1×1的卷积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T02:42:55.135973Z",
     "start_time": "2017-10-16T02:42:55.122938Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义一个这样的块，它由一个正常的卷积层接上两个kernel是1×11×1的卷积层构成。后面两个充当两个全连接层的角色\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "def mlpconv(channels, kernel_size, padding,\n",
    "            strides=1, max_pooling=True):\n",
    "    out = nn.Sequential()\n",
    "    with out.name_scope():        \n",
    "        out.add(nn.Conv2D(channels=channels, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      activation='relu'))\n",
    "        out.add(nn.Conv2D(channels=channels, kernel_size=1,\n",
    "                      padding=0, strides=1, activation='relu'))\n",
    "        out.add(nn.Conv2D(channels=channels, kernel_size=1,\n",
    "                      padding=0, strides=1, activation='relu'))\n",
    "        if max_pooling:\n",
    "            out.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T02:42:59.248340Z",
     "start_time": "2017-10-16T02:42:59.227785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64, 6, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "from mxnet import nd\n",
    "\n",
    "blk = mlpconv(64, 3, 0)\n",
    "blk.initialize()\n",
    "\n",
    "x = nd.random.uniform(shape=(32, 3, 16, 16))\n",
    "y = blk(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NiN的卷积层的参数跟Alexnet类似，使用三组不同的设定\n",
    "\n",
    "kernel: 11×11, channels: 96\n",
    "kernel: 5×5, channels: 256\n",
    "kernel: 3×3, channels: 384\n",
    "除了使用了1×11×1卷积外，NiN在最后不是使用全连接，而是使用通道数为输出类别个数的mlpconv，外接一个平均池化层来将每个通道里的数值平均成一个标量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T02:49:05.004443Z",
     "start_time": "2017-10-16T02:49:02.900194Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3a554e88b3f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtry_gpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXavier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgluon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoftmaxCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "#跟Alexnet类似，但使用了更大的学习率\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from mxnet import gluon\n",
    "from mxnet import init\n",
    "\n",
    "train_data, test_data = utils.load_data_fashion_mnist(\n",
    "    batch_size=64, resize=224)\n",
    "\n",
    "ctx = utils.try_gpu()\n",
    "net.initialize(ctx=ctx, init=init.Xavier())\n",
    "\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                        'sgd', {'learning_rate': 0.1})\n",
    "utils.train(train_data, test_data, net, loss,\n",
    "            trainer, ctx, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
